{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to difficulties converting a Pytorch model to a Tensorflow model, this notebook uses the same CNN model as before, but written in Tensorflow. This allows it to be portable to an Android device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as path\n",
    "import librosa\n",
    "\n",
    "import build.pybind_modules.dsp_module as cu\n",
    "import build.pybind_modules.matrix_module as myMatrix\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.math import confusion_matrix\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "from tflite_runtime.interpreter import Interpreter\n",
    "\n",
    "print('TensorFlow version:',tf.__version__)\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "for dev in physical_devices:\n",
    "    print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "MODEL_NAME = 'audio_mnist'\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "FS = 48000\n",
    "DOWNSAMPLED_FS = 8000\n",
    "NFFT = 256\n",
    "NOVERLAP = -1\n",
    "NFILT = 40\n",
    "NUM_CEPS = 13\n",
    "NN_DATA_COLS = 48\n",
    "NN_DATA_ROWS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu6(x):\n",
    "    return tf.keras.activations.relu(x, max_value=6)\n",
    "\n",
    "def compute_accuracies(predicted_labels, dev_set, dev_labels):\n",
    "    yhats = predicted_labels\n",
    "    assert predicted_labels.dtype == int, \"Your predicted labels have type {}, but they should have type np.int (consider using .astype(int) on your output)\".format(predicted_labels.dtype)\n",
    "\n",
    "    if len(yhats) != len(dev_labels):\n",
    "        print(\"Lengths of predicted labels don't match length of actual labels\", len(yhats), len(dev_labels))\n",
    "        return 0., 0., 0., 0.\n",
    "    accuracy = np.mean(yhats == dev_labels)\n",
    "    conf_m = np.zeros((len(np.unique(dev_labels)),len(np.unique(dev_labels))))\n",
    "    for i,j in zip(dev_labels,predicted_labels):\n",
    "        conf_m[i,j] +=1\n",
    "\n",
    "    return accuracy, conf_m\n",
    "\n",
    "def export_model(saver, model, input_node_names, output_node_name):\n",
    "    tf.train.write_graph(K.get_session().graph_def, 'out', \\\n",
    "        MODEL_NAME + '_graph.pbtxt')\n",
    "\n",
    "    saver.save(K.get_session(), 'out/' + MODEL_NAME + '.chkp')\n",
    "\n",
    "    freeze_graph.freeze_graph('out/' + MODEL_NAME + '_graph.pbtxt', None, \\\n",
    "        False, 'out/' + MODEL_NAME + '.chkp', output_node_name, \\\n",
    "        \"save/restore_all\", \"save/Const:0\", \\\n",
    "        'out/frozen_' + MODEL_NAME + '.pb', True, \"\")\n",
    "\n",
    "    input_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.Open('out/frozen_' + MODEL_NAME + '.pb', \"rb\") as f:\n",
    "        input_graph_def.ParseFromString(f.read())\n",
    "\n",
    "    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "            input_graph_def, input_node_names, [output_node_name],\n",
    "            tf.float32.as_datatype_enum)\n",
    "\n",
    "    with tf.gfile.FastGFile('out/opt_' + MODEL_NAME + '.pb', \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "    print(\"graph saved!\")\n",
    "\n",
    "\n",
    "class NeuralNet(tf.keras.Model):\n",
    "    def __init__(self, out_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=10, kernel_size=(3,3), activation=relu6, padding='same', kernel_initializer='he_uniform')\n",
    "        self.maxpool = tf.keras.layers.MaxPooling2D(pool_size=(3,3), padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=20, kernel_size=(3,3), activation=relu6, padding='same', kernel_initializer='he_uniform')\n",
    "        self.dropout_1 = tf.keras.layers.Dropout(rate=0.1)\n",
    "        self.dropout_2 = tf.keras.layers.Dropout(rate=0.16)\n",
    "        self.dropout_3 = tf.keras.layers.Dropout(rate=0.12)\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense_1 = tf.keras.layers.Dense(units=5000, activation='relu', kernel_initializer='he_uniform')\n",
    "        self.dense_2 = tf.keras.layers.Dense(units=1000, activation='relu', kernel_initializer='he_uniform')\n",
    "        self.dense_3 = tf.keras.layers.Dense(units=out_size, activation='softmax', kernel_initializer='he_uniform')\n",
    "\n",
    "        # self.loss_fn = loss_fn\n",
    "        # self.optimizer = tf.keras.optimizers.SGD(learning_rate=lrate, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout_1(x, training=True)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dropout_2(x, training=True)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.dropout_3(x, training=True)\n",
    "        x = self.dense_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len dev_set_labels: 200\n",
      "Len dev_set: 200\n",
      "Len train_set_labels: 1000\n",
      "Len train_set: 1000\n",
      "\n",
      "Trainset shape: (1000, 576)\n"
     ]
    }
   ],
   "source": [
    "# Load the data (should be trained and uploaded using the other spoken_digit_recognition notebook)\n",
    "\n",
    "dev_set_labels = np.loadtxt(\"l_dev_set_labels.csv\", delimiter=\",\", dtype=np.int32)\n",
    "train_labels = np.loadtxt(\"train_labels.csv\", delimiter=\",\", dtype=np.int32)\n",
    "train_set = np.loadtxt(\"train_set.csv\", delimiter=\",\", dtype=np.float64)\n",
    "dev_set = np.loadtxt(\"dev_set.csv\", delimiter=\",\", dtype=np.float64)\n",
    "\n",
    "print(\"Len dev_set_labels: {}\".format(len(dev_set_labels)))\n",
    "print(\"Len dev_set: {}\".format(len(dev_set_labels)))\n",
    "print(\"Len train_set_labels: {}\".format(len(train_labels)))\n",
    "print(\"Len train_set: {}\".format(len(train_set)))\n",
    "\n",
    "print(\"\\nTrainset shape: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping data to desired shape\n",
    "reshaped_dev_set = np.zeros((len(dev_set), NN_DATA_ROWS, NN_DATA_COLS))\n",
    "reshaped_train_set = np.zeros((len(train_set), NN_DATA_ROWS, NN_DATA_COLS))\n",
    "for i in range(len(dev_set)):\n",
    "    reshaped_dev_set[i] = np.reshape(dev_set[i], (NN_DATA_ROWS, NN_DATA_COLS))\n",
    "\n",
    "for i in range(len(train_set)):\n",
    "    reshaped_train_set[i] = np.reshape(train_set[i], (NN_DATA_ROWS, NN_DATA_COLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 12, 48, 1)]       0         \n",
      "                                                                 \n",
      " neural_net (NeuralNet)      (None, 10)                6217930   \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| conv2d (Conv2D)           multiple                  100       |\n",
      "|                                                               |\n",
      "| max_pooling2d (MaxPooling2D  multiple               0         |\n",
      "| )                                                             |\n",
      "|                                                               |\n",
      "| conv2d_1 (Conv2D)         multiple                  1820      |\n",
      "|                                                               |\n",
      "| dropout (Dropout)         multiple                  0         |\n",
      "|                                                               |\n",
      "| dropout_1 (Dropout)       multiple                  0         |\n",
      "|                                                               |\n",
      "| dropout_2 (Dropout)       multiple                  0         |\n",
      "|                                                               |\n",
      "| flatten (Flatten)         multiple                  0         |\n",
      "|                                                               |\n",
      "| dense (Dense)             multiple                  1205000   |\n",
      "|                                                               |\n",
      "| dense_1 (Dense)           multiple                  5001000   |\n",
      "|                                                               |\n",
      "| dense_2 (Dense)           multiple                  10010     |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "=================================================================\n",
      "Total params: 6,217,930\n",
      "Trainable params: 6,217,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# running dataset on model \n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "input_dim = 12 # num ceps - 1\n",
    "output_dim = 10 # number of genres\n",
    "weight_decay = 1e-2\n",
    "learning_rate = 1e-2\n",
    "\n",
    "input_layer = Input(shape=(NN_DATA_ROWS, NN_DATA_COLS, 1))\n",
    "x = NeuralNet(output_dim)(input_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# printing a view of the model\n",
    "print(model.summary(expand_nested=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 28ms/step - loss: 10.4192 - val_loss: 2.2412\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.0840 - val_loss: 1.9260\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.7583 - val_loss: 1.5916\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.4271 - val_loss: 1.3260\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.1283 - val_loss: 1.0115\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.8055 - val_loss: 0.8343\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6520 - val_loss: 0.7425\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4878 - val_loss: 0.4859\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3872 - val_loss: 0.5273\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3495 - val_loss: 0.4757\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2708 - val_loss: 0.3210\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2701 - val_loss: 0.3560\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2022 - val_loss: 0.3359\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1866 - val_loss: 0.2575\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1630 - val_loss: 0.3206\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1786 - val_loss: 0.2271\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1406 - val_loss: 0.3019\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1301 - val_loss: 0.2710\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1429 - val_loss: 0.2230\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1112 - val_loss: 0.1935\n"
     ]
    }
   ],
   "source": [
    "# training the model now\n",
    "# model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, weight_decay=weight_decay), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=\"acc\")\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, weight_decay=weight_decay), loss=tf.keras.losses.SparseCategoricalCrossentropy())\n",
    "history = model.fit(x=reshaped_train_set, y=train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(reshaped_dev_set, dev_set_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# confusion = confusion_matrix(labels=dev_set_labels, predictions=, num_classes=num_classes)\n",
    "# print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 prections by (value, label)\n",
      "[(0.98286, 8), (0.012504478, 9), (0.0035975103, 0)]\n",
      "Actual label was: 8\n",
      "\n",
      "Top 3 prections by (value, label)\n",
      "[(0.9820525, 1), (0.012819302, 4), (0.0034329419, 3)]\n",
      "Actual label was: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing a prediction on the model\n",
    "dev_set_1_idx = 20\n",
    "dev_set_2_idx = 180\n",
    "single_test = tf.convert_to_tensor(np.array([reshaped_dev_set[dev_set_1_idx], reshaped_dev_set[dev_set_2_idx]]))\n",
    "predictions = model(single_test, training=False).numpy()\n",
    "\n",
    "print(\"Top 3 prections by (value, label)\")\n",
    "print(sorted(zip(predictions[0], [i for i in range(10)]), reverse=True)[:3])\n",
    "print(\"Actual label was: {}\\n\".format(dev_set_labels[dev_set_1_idx]))\n",
    "\n",
    "print(\"Top 3 prections by (value, label)\")\n",
    "print(sorted(zip(predictions[1], [i for i in range(10)]), reverse=True)[:3])\n",
    "print(\"Actual label was: {}\\n\".format(dev_set_labels[dev_set_2_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayFIR(filt):\n",
    "    coef_str = \"{\" \n",
    "    for val in filt: \n",
    "        coef_str += str(val) + \", \" \n",
    "    coef_str = coef_str[:-2] \n",
    "    coef_str += \"};\" \n",
    "    print(\"FIR a Coefficients\")\n",
    "    print(coef_str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIR a Coefficients\n",
      "{4.608795255997088, 6.698753287757723, 8.236016873501589, 7.700499116598714, 5.245252962919166, 3.8466566539754545, 0.2557723577548203, -2.224424702878995, -1.7538192820271359, -1.6108894693193423, -1.5526189819315854, -1.4217778875485052, 0.6884055890191354, 0.19267831195985646, 2.3121828630044594, 4.709698465608981, 4.254232469349811, 4.867784266241455, 3.6521102731532706, 5.176660526987325, 5.1262866046084, 7.18305450651508, 7.307006051256813, 9.797304678514347, 6.722168772648709, 7.086903804628322, 2.1571777229279383, 2.0079520449434693, -0.6501586804137662, -3.51383108746593, -3.809193133424525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};\n"
     ]
    }
   ],
   "source": [
    "displayFIR(reshaped_dev_set[dev_set_1_idx][11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 19:48:35.673139: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,2,6,20]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 19:48:35.694500: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5000]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 19:48:35.711266: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1000]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 19:48:36.200094: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,2,6,20]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 19:48:36.221770: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5000]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 19:48:36.242516: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1000]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model/assets\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_1_layer_call_fn while saving (showing 5 of 21). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpuubgckse/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpuubgckse/assets\n",
      "2023-04-20 19:48:38.537047: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-04-20 19:48:38.537076: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-04-20 19:48:38.537471: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpuubgckse\n",
      "2023-04-20 19:48:38.538943: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-04-20 19:48:38.538963: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpuubgckse\n",
      "2023-04-20 19:48:38.542368: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
      "2023-04-20 19:48:38.543484: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-04-20 19:48:38.587917: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpuubgckse\n",
      "2023-04-20 19:48:38.602855: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 65385 microseconds.\n",
      "2023-04-20 19:48:38.624812: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "model.save('my_model')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('my_model')\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted model\n",
    "with open('my_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output data: [[1.3611508e-03 3.5230021e-04 2.9098062e-06 2.4490946e-06 3.4021759e-05\n",
      "  5.2604580e-04 8.8414885e-03 1.0675494e-04 9.8448426e-01 4.2886338e-03]]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "model_path = 'my_model.tflite'\n",
    "interpreter = Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "single_test = np.reshape(np.array(reshaped_dev_set[dev_set_1_idx], dtype=np.float32), (1, 12, 48, 1))\n",
    "interpreter.set_tensor(input_details[0]['index'], single_test)\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Output data: {}\".format(output_data))\n",
    "print(np.argmax(output_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
